{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d95d1bf0-4eab-4d74-ab94-3e3f94cc8b7c",
   "metadata": {},
   "source": [
    "Генерируем описание недвижимости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "577ace00-c7f7-4073-bbcd-36c712005721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vladimirnikitin/miniconda3/envs/env/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A photo of a kitchen with modern style\n",
      "CPU times: user 660 ms, sys: 1.09 s, total: 1.75 s\n",
      "Wall time: 138 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vladimirnikitin/miniconda3/envs/env/lib/python3.11/site-packages/transformers/generation/logits_process.py:156: UserWarning: The operator 'aten::isin.Tensor_Tensor_out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:13.)\n",
      "  eos_token_mask = torch.isin(vocab_tensor, eos_token_id)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'a kitchen with white cabinets and a table in the middle of the room'}]\n",
      "CPU times: user 1.49 s, sys: 1.64 s, total: 3.13 s\n",
      "Wall time: 927 ms\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from transformers import CLIPProcessor, CLIPModel, pipeline\n",
    "\n",
    "model_name = \"openai/clip-vit-base-patch32\"\n",
    "processor = CLIPProcessor.from_pretrained(model_name)\n",
    "model = CLIPModel.from_pretrained(model_name)\n",
    "\n",
    "#сначала я попробовал в промпт инжиниринг\n",
    "\n",
    "text_prompts = [\n",
    "    \"A photo of a kitchen with sink, bar table and dining table and beautiful lighting\",\n",
    "    \"A photo of a kitchen in excellent condition\",\n",
    "    \"A photo of a kitchen with modern style\",\n",
    "    \"A photo of a kitchen needing repair\",\n",
    "    \"A photo of a living room in excellent condition\",\n",
    "    \"A photo of a living room with fully stacked furniture\",\n",
    "    \"A photo of a living room with contemporary style\",\n",
    "    \"A photo of a living room needing repair\",\n",
    "    \"A photo of a bathroom in excellent condition\",\n",
    "    \"A photo of a bathroom with luxury style\",\n",
    "    \"A photo of a bathroom needing repair\",\n",
    "    \"A photo of a house exterior in excellent condition\",\n",
    "    \"A photo of a house exterior with modern architecture\",\n",
    "    \"A photo of a house exterior needing repair\"\n",
    "    # Add more prompts as needed\n",
    "]\n",
    "\n",
    "def generate_description(image_path):\n",
    "    # Load the image from the file path\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Process the image\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    image_features = model.get_image_features(pixel_values=inputs.pixel_values)\n",
    "    \n",
    "    # Process the text prompts\n",
    "    text_inputs = processor(text=text_prompts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    text_features = model.get_text_features(input_ids=text_inputs.input_ids)\n",
    "    \n",
    "    # Calculate similarities\n",
    "    similarities = cosine_similarity(text_features, image_features.unsqueeze(0), dim=-1)\n",
    "    \n",
    "    # Find the highest similarity score\n",
    "    max_index = similarities.argmax()\n",
    "    # Return the most matching description\n",
    "    return text_prompts[max_index]\n",
    "\n",
    "%time print(generate_description('imgs/kitchen1.jpeg'))\n",
    "\n",
    "# хотя вот так мы имеем более точный, но что самое главное - уникальный промпт каждый раз\n",
    "\n",
    "captioner = pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-base\", device='mps')\n",
    "%time print(captioner('imgs/kitchen1.jpeg', max_new_tokens=200, generate_kwargs={\"min_length\": 10}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1b36f6a-0eeb-4927-8a42-eaa366adb6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.27 s, sys: 1.61 s, total: 2.88 s\n",
      "Wall time: 662 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'a house with a blue roof and white trim on the front of it, with a brick chimney and a brick chimney and'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time captioner('imgs/ext1.jpeg', max_new_tokens=24, generate_kwargs={\"min_length\": 24})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69e3109c-908a-42df-a8a0-de5bb898605a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.13 s, sys: 1.49 s, total: 2.62 s\n",
      "Wall time: 481 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"a bathroom with a tub and a sink in it's corner, with a mirror above the tub and a shower head\"}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time captioner('imgs/bath1.jpeg', max_new_tokens=1000, generate_kwargs={\"min_length\": 24})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6a85bed-a1b8-4a4a-9739-c8d80e8f1ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ab8c32-c6df-4a43-a9da-49d1d9de2b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5683628a-ce6d-4898-b910-17f98830406f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef1ee982-b882-407a-9bea-26db8324d66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import os\n",
    "\n",
    "def preprocess_images(image_paths):\n",
    "    images = []\n",
    "    for image_path in image_paths:\n",
    "        if os.path.exists(image_path):\n",
    "            img = Image.open(image_path).convert(\"RGB\")\n",
    "            images.append(img)\n",
    "        else:\n",
    "            print(f\"Warning: Image at {image_path} not found.\")\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f06abc5d-4b53-4905-874e-2b2bec807e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#пойдем немного по-другому пути"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "698fe9f2-bc57-416e-88ce-b2effebc9583",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "from deep_translator import GoogleTranslator\n",
    "import sentencepiece\n",
    "import numpy as np\n",
    "\n",
    "device = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56cda25-cd91-49b4-ae92-914fe5db5669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# на этом моменте я понял, что 40 гб оперативы и такое время инференса на этапе 2 противоречит дальнейшему развитию работы c\n",
    "# llava, как бы мне и нравится результат, но капец какими усилиями он добывается + не по тз заказчика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa8c2e5-4a08-4eb9-9ffb-6617c3999f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enot quantize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87047cba-8f5f-4f4b-b4e0-78ba7ab88a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bert score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a8fa2c-e56f-4fa8-8243-6b4000cd19eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#описание проекта модели и что она делает схема архитектуры и инференс "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e16745-04af-4968-8ce8-96d1e464cf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавить доп обратку по разным параметрам введенного пользователя типа объявлений -\n",
    "# проверка количества комнат для генерации описания по одной (если комната представлена на разных фото)\n",
    "# сложность в повторении элементов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31bd877d-5f5d-474f-b33f-db9cbac68631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# с помощью быстрого, но короткого описания можно узнавать тип помещения, а дальше использовать знания для группировки комнат по количеству\n",
    "# исходя из вводных данных. Плюс можно задать контекст для следующих обработок картинок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8125196f-8022-47bc-b2dd-c0f5969a4fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# продать/сдать длительно/сдать суточно (1/2/3) \n",
    "# 1 - квартира, 2 - комната, 3 - дом, 4 - коммерческое, 5 - гараж, 6 - участок (123456 / 12345 / 123)\n",
    "# 1:\n",
    "# город (string)\n",
    "# улица (string)\n",
    "# год постройки (int)\n",
    "# высота потолков (float)\n",
    "# тип парковки (1 - закрытая /2 - подземная /3 - открытая)\n",
    "# тип дома (1 - кирпич/ 2 - монолит / 3 - кирпич-монолит / 4 - панель / 5 - блок)\n",
    "# комнаты (0/1/2/3/4/5/6/7)\n",
    "# площадь (float, float, float)\n",
    "# этаж (int/int)\n",
    "# статус (1 - апартаменты / 2 - жилое)\n",
    "# санузел (1 - совмещенный / 2 - раздельный / 3 - более одного)\n",
    "# балкон (0 / 1 - балкон / 2 - лоджия / 3 - несколько)\n",
    "# ремонт (1 - косметический / 2 - евро / 3 - дизайнерский / 4 - требуется)\n",
    "# окна (1 - во двор / 2 - на улицу)\n",
    "# удобства (1 - интернет / 2 - холодильник / 3 - мебель на кухне / 4 - кондиционер / 5 - мебель в квартире / 6 - лифт / 7 - мусоропровод\n",
    "# / 8 - консьерж / 9 - закрытая территория)\n",
    "\n",
    "# видео (url)\n",
    "# фото планировки\n",
    "# фото объекта (до 30 шт)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "fbcc7ed7-644e-4332-9e5c-af2582b4c1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classify_room(image):\n",
    "    #output = image_to_text(image, prompt=prompt, generate_kwargs={\"max_new_tokens\": 200})\n",
    "    output = captioner(image, generate_kwargs={\"max_new_tokens\": 200, \"min_length\": 25})\n",
    "    description = output[0]['generated_text']\n",
    "    \n",
    "    office_keywords = [\"office\", \"workspace\", \"desk\", \"meeting room\"]\n",
    "    residential_keywords = [\"bedroom\", \"living room\", \"kitchen\", \"bathroom\"]\n",
    "    commercial_keywords = [\"store\", \"shop\", \"warehouse\"]\n",
    "    exterior_keywords = [\"house\", 'outdoors', 'outside']\n",
    "\n",
    "    description_lower = description.lower()\n",
    "\n",
    "    if any(keyword in description_lower for keyword in office_keywords):\n",
    "        return \"office\", description\n",
    "    elif any(keyword in description_lower for keyword in residential_keywords):\n",
    "        return \"residential\", description\n",
    "    elif any(keyword in description_lower for keyword in commercial_keywords):\n",
    "        return \"commercial\", description\n",
    "    elif any(keyword in description_lower for keyword in exterior_keywords):\n",
    "        return \"exterior\", description\n",
    "    else:\n",
    "        return \"unknown\", description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "24c306b6-a930-47a4-b058-160c1a287bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import language_tool_python\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def postprocess_text(text):\n",
    "    tool = language_tool_python.LanguageTool('ru-RU')\n",
    "    matches = tool.check(text)\n",
    "    corrected_text = language_tool_python.utils.correct(text, matches)\n",
    "    return corrected_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "a25b0da5-3268-44fa-bc4c-d3fa8d4591bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_descriptions_old(room_classifications, rooms):\n",
    "    combined_text = '\\n' \n",
    "    combined_text += \"This object includes the following:\"\n",
    "    for room in room_classifications:\n",
    "        combined_text += '\\n' \n",
    "        combined_text += room[1]\n",
    "        \n",
    "def combine_descriptions(rooms, room_classifications):\n",
    "    \n",
    "    combined_text = generate_clusters_description(rooms, room_classifications)\n",
    "    return combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "0cd6d310-1689-4b3c-8668-197486bdb317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vladimirnikitin/miniconda3/envs/env/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'The universe is the universe.'}]\n",
      "{'тип объявления': 'продать', 'тип недвижимости': 'квартира', 'город': 'Санкт', 'адрес': 'Петербург 3', 'год постройки': 1703, 'высота потолков': 3, 'тип парковки': 'закрытая', 'тип дома': 'кирпич', 'комнаты': 2, 'площадь': '30', 'этаж': '3/5', 'статус': 'апартаменты', 'санузел': 'совмещенный', 'балкон': 'балкон', 'ремонт': 'косметический', 'окна': 'во двор', 'удобства': ['интернет', 'мусоропровод', 'холодильник', 'закрытая территория', 'кондиционер']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'тип объявления': 'продать', 'тип недвижимости': 'квартира', 'город': 'Санкт', 'адрес': 'Петербург 3', 'год постройки': 1703, 'высота потолков': 3, 'тип парковки': 'закрытая', 'тип дома': 'кирпич', 'комнаты': 2, 'площадь': '30', 'этаж': '3/5', 'статус': 'апартаменты', 'санузел': 'совмещенный', 'балкон': 'балкон', 'ремонт': 'косметический', 'окна': 'во двор', 'удобства': ['интернет', 'мусоропровод', 'холодильник', 'закрытая территория', 'кондиционер']}\n"
     ]
    }
   ],
   "source": [
    "###### здесь делаем запрос к API HuggingFace - нестабильно и лучше переписать ######\n",
    "\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"cointegrated/rut5-base-multitask\")\n",
    "clustermodel = T5ForConditionalGeneration.from_pretrained(\"cointegrated/rut5-base-multitask\")\n",
    "\n",
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/cointegrated/rut5-base-multitask\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\t\n",
    "output = query({\n",
    "\t\"inputs\": \"assemble | The answer to the universe is\", \"min_length\": 25\n",
    "})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "e3939adc-4900-4e64-9c03-7c948c167c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_room_description(cluster_text):\n",
    "    # Используем модель ruT5 для извлечения сущностей и их описаний\n",
    "    input_text = f\"assemble | {cluster_text}\"\n",
    "    output = query({\"inputs\": f\"assemble | {cluster_text}\"}, )\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "3e61d2df-5418-4ab2-9435-348524ea5f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Загрузка предобученной модели и токенизатора\n",
    "model_name = \"sberbank-ai/sbert_large_nlu_ru\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(**inputs)[0]\n",
    "    return embeddings.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "def generate_clusters_description(n_clusters, room_descriptions):\n",
    "    # Получение эмбеддингов описаний\n",
    "    embeddings = [get_embeddings(desc) for desc in room_descriptions]\n",
    "    embeddings = np.concatenate(embeddings, axis=0)\n",
    "    # Вычисление косинусного сходства\n",
    "    similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "    # Кластеризация описаний\n",
    "    kmeans = KMeans(n_clusters=n_clusters+2, random_state=42).fit(embeddings)\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    # Генерация сводных описаний для каждого кластера\n",
    "    cluster_descriptions = []\n",
    "    for i in range(n_clusters+2):\n",
    "        cluster_desc = \" \".join([room_descriptions[j // 2][1] for j in range(len(labels)) if labels[j] == i])\n",
    "        cluster_desc = GoogleTranslator(source='auto', target='ru').translate(cluster_desc)\n",
    "        cluster_desc = generate_room_description(cluster_desc)\n",
    "        cluster_descriptions.append(cluster_desc[0]['generated_text'])\n",
    "\n",
    "    # Формирование итогового описания\n",
    "    final_description = \"Этот объект включает в себя следующие комнаты:\\n\"\n",
    "    final_description += \"\\n\".join(cluster_descriptions)\n",
    "\n",
    "    return final_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "8bd19ce5-8200-4026-aadd-9d20b68efea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.util import ngrams\n",
    "from textblob import TextBlob\n",
    "from textstat import flesch_reading_ease\n",
    "\n",
    "def perplexity(text, n=3):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    n_grams = list(ngrams(tokens, n))\n",
    "    vocab = set(tokens)\n",
    "    perplexity_score = 0\n",
    "\n",
    "    for gram in n_grams:\n",
    "        prefix = gram[:-1]\n",
    "        prob = n_grams.count(gram) / len(n_grams)\n",
    "        perplexity_score += math.log(prob, 2)\n",
    "\n",
    "    perplexity_score = math.pow(2, -perplexity_score / len(n_grams))\n",
    "    return perplexity_score\n",
    "\n",
    "def entropy(text):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    freq_dist = nltk.FreqDist(tokens)\n",
    "    probs = [freq_dist.freq(token) for token in freq_dist]\n",
    "    entropy_score = -sum(p * math.log(p, 2) for p in probs)\n",
    "    return entropy_score\n",
    "\n",
    "def grammatical_correctness(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.correct().string\n",
    "\n",
    "def text_coherence(text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    sentence_vectors = [nltk.word_tokenize(sentence.lower()) for sentence in sentences]\n",
    "    similarity_scores = []\n",
    "\n",
    "    for i in range(len(sentence_vectors) - 1):\n",
    "        similarity = sentence_bleu([sentence_vectors[i]], sentence_vectors[i + 1], weights=(1, 0, 0, 0))\n",
    "        similarity_scores.append(similarity)\n",
    "\n",
    "    coherence_score = sum(similarity_scores) / len(similarity_scores)\n",
    "    return coherence_score\n",
    "\n",
    "def readability(text):\n",
    "    readability_score = flesch_reading_ease(text)\n",
    "    return readability_score\n",
    "\n",
    "def metrics(generated_text):\n",
    "    perplexity_score = perplexity(generated_text)\n",
    "    entropy_score = entropy(generated_text)\n",
    "    corrected_text = grammatical_correctness(generated_text)\n",
    "    coherence_score = text_coherence(generated_text)\n",
    "    readability_score = readability(generated_text)\n",
    "\n",
    "    print(\"Perplexity:\", perplexity_score)\n",
    "    print(\"Entropy:\", entropy_score)\n",
    "    print(\"Grammatically corrected text:\", corrected_text)\n",
    "    print(\"Text coherence:\", coherence_score)\n",
    "    print(\"Readability:\", readability_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "d539405d-386a-4eca-886a-d2276edd190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def process_images(image_paths, data):\n",
    "    processed_images = preprocess_images(image_paths)\n",
    "    data = eval(data)\n",
    "    combined = combined_output(data)\n",
    "    room_classifications = [classify_room(img) for img in processed_images]\n",
    "    full_description = combine_descriptions(data['комнаты'], room_classifications)\n",
    "    full_description = GoogleTranslator(source='auto', target='ru').translate(full_description)\n",
    "    torch.mps.empty_cache()\n",
    "    metka = \"Обратите внимание, что данное описание было создано автоматически с помощью технологий искусственного интеллекта и служит исключительно в качестве примера. Фактические характеристики объекта могут отличаться.\"\n",
    "    #metrics(combined + '\\n' + full_description)\n",
    "    return combined + '\\n' + full_description + '\\n * ' + metka\n",
    "\n",
    "def preprocess_images(image_paths):\n",
    "    images = []\n",
    "    if image_paths is not None:\n",
    "        for image_path in image_paths:\n",
    "            if image_path is not None and os.path.isfile(image_path):\n",
    "                img = Image.open(image_path).convert(\"RGB\")\n",
    "                images.append(img)\n",
    "            else:\n",
    "                print(f\"Warning: Invalid image path: {image_path}\")\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "7fdc56d8-84da-42bf-a5ea-3c94dd8169b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_output(metadata):\n",
    "    # Создаем список для хранения частей текста\n",
    "    output_parts = []\n",
    "    print(metadata)\n",
    "    # Добавляем вводную часть объявления\n",
    "    if(metadata['тип объявления'] == \"продать\"):\n",
    "        output_parts.append(f\"Продается {metadata['тип недвижимости']} в городе {metadata['город']}. \")\n",
    "    if(metadata['тип объявления'] == \"сдать длительно\"):\n",
    "        output_parts.append(f\"Предлагается к длительной аренде {metadata['тип недвижимости']} в городе {metadata['город']}. \")\n",
    "    if(metadata['тип объявления'] == \"сдать суточно\"):\n",
    "        output_parts.append(f\"Предлагается к посуточной аренде {metadata['тип недвижимости']} в городе {metadata['город']}. \")\n",
    "    output_parts.append(f\"Объект расположен по адресу: {metadata['адрес']}. \")\n",
    "\n",
    "    # Добавляем информацию о здании\n",
    "    if(metadata['тип дома']):\n",
    "        output_parts.append(f\"Здание построено в {metadata['год постройки']} году, тип дома - {metadata['тип дома']}. \")\n",
    "    else:\n",
    "        output_parts.append(f\"Здание построено в {metadata['год постройки']} году. \")\n",
    "    if(metadata['статус']):\n",
    "        output_parts.append(f\"Квартира имеет статус {metadata['статус']}. \")\n",
    "\n",
    "    if(metadata['высота потолков']):\n",
    "        output_parts.append(f\"Высота потолков составляет {metadata['высота потолков']} м. \")\n",
    "\n",
    "    # Добавляем информацию о квартире\n",
    "    if(metadata['этаж']):\n",
    "        output_parts.append(f\"Квартира находится на {metadata['этаж']} этаже и имеет {metadata['комнаты']} комнаты. \")\n",
    "    output_parts.append(f\"Общая площадь составляет {metadata['площадь']} кв.м. \")\n",
    "    \n",
    "\n",
    "    # Добавляем информацию о ремонте и удобствах\n",
    "    if(metadata['ремонт']):\n",
    "        output_parts.append(f\"В квартире выполнен {metadata['ремонт']} ремонт. \")\n",
    "        output_parts.append(f\"Санузел {metadata['санузел']}, имеется {metadata['балкон']}. \")\n",
    "    if(metadata['окна']):\n",
    "        output_parts.append(f\"Окна выходят {metadata['окна']}. \")\n",
    "\n",
    "    # Добавляем информацию об удобствах\n",
    "    if(metadata['удобства']):\n",
    "        amenities = \", \".join(metadata['удобства'])\n",
    "        output_parts.append(f\"Квартира оборудована следующими удобствами: {amenities}. \")\n",
    "\n",
    "    # Добавляем информацию о парковке\n",
    "    output_parts.append(f\"Рядом с домом имеется {metadata['тип парковки']} парковка. \")\n",
    "\n",
    "    # Добавляем описания комнат\n",
    "    # output_parts.append(\"Описание комнат:\")\n",
    "    # for room_description in room_descriptions:\n",
    "    #     output_parts.append(f\"- {room_description}\")\n",
    "    # output_parts.append(f\"- {room_descriptions}\")\n",
    "    \n",
    "    # Объединяем все части текста в единый текст\n",
    "    output_text = \"\".join(output_parts)\n",
    "\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "f7816664-d0e0-4ffe-8768-84aaf7db997f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7872\n",
      "Running on public URL: https://c716ca7521f78c4340.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://c716ca7521f78c4340.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def parse_real_estate_data(ad_type, property_type, city, address, year, ceiling_height, parking_type, house_type, rooms, area, floor, status, bathroom, balcony, renovation, windows, amenities):\n",
    "    # Создаем словарь для хранения данных\n",
    "    real_estate_data = {\n",
    "        'тип объявления': ad_type,\n",
    "        'тип недвижимости': property_type,\n",
    "        'город': city,\n",
    "        'адрес': address,\n",
    "        'год постройки': year,\n",
    "        'высота потолков': ceiling_height,\n",
    "        'тип парковки': parking_type,\n",
    "        'тип дома': house_type,\n",
    "        'комнаты': rooms,\n",
    "        'площадь': area,\n",
    "        'этаж': floor,\n",
    "        'статус': status,\n",
    "        'санузел': bathroom,\n",
    "        'балкон': balcony,\n",
    "        'ремонт': renovation,\n",
    "        'окна': windows,\n",
    "        'удобства': amenities\n",
    "    }\n",
    "    \n",
    "    # Возвращаем собранные данные\n",
    "    return str(real_estate_data)\n",
    "\n",
    "def update_property_type_choices(ad_type):\n",
    "    if ad_type == \"продать\":\n",
    "        return gr.Dropdown(choices=[\"квартира\", \"комната\", \"дом\", \"коммерческое\", \"гараж\", \"участок\"])\n",
    "    elif ad_type == \"сдать длительно\":\n",
    "        return gr.Dropdown(choices=[\"квартира\", \"комната\", \"дом\", \"коммерческое\", \"гараж\"])\n",
    "    else:\n",
    "        return gr.Dropdown(choices=[\"квартира\", \"комната\", \"дом\", \"коммерческое\"])\n",
    "\n",
    "def update_visibility(property_type):\n",
    "    if property_type in [\"гараж\", \"участок\"]:\n",
    "        return [\n",
    "            gr.update(visible=True),  # Площадь\n",
    "            gr.update(visible=False),  # Комнаты\n",
    "            gr.update(visible=False),  # Тип дома\n",
    "            gr.update(visible=False),  # Этаж\n",
    "            gr.update(visible=False),  # Статус\n",
    "            gr.update(visible=False),  # Санузел\n",
    "            gr.update(visible=False),  # Балкон\n",
    "            gr.update(visible=False),  # Ремонт\n",
    "            gr.update(visible=False),  # Окна\n",
    "            gr.update(visible=False)   # Удобства\n",
    "        ]\n",
    "    elif property_type in [\"дом\", \"коммерческое\"]:\n",
    "        return [\n",
    "            gr.update(visible=True),  # Площадь\n",
    "            gr.update(visible=True),  # Комнаты\n",
    "            gr.update(visible=True),  # Тип дома\n",
    "            gr.update(visible=True),  # Этаж\n",
    "            gr.update(visible=False),  # Статус\n",
    "            gr.update(visible=True),  # Санузел\n",
    "            gr.update(visible=True),  # Балкон\n",
    "            gr.update(visible=True),  # Ремонт\n",
    "            gr.update(visible=False),  # Окна\n",
    "            gr.update(visible=True)   # Удобства\n",
    "        ]\n",
    "    else:\n",
    "        return [\n",
    "            gr.update(visible=True),  # Площадь\n",
    "            gr.update(visible=True),  # Комнаты\n",
    "            gr.update(visible=True),  # Тип дома\n",
    "            gr.update(visible=True),  # Этаж\n",
    "            gr.update(visible=True),  # Статус\n",
    "            gr.update(visible=True),  # Санузел\n",
    "            gr.update(visible=True),  # Балкон\n",
    "            gr.update(visible=True),  # Ремонт\n",
    "            gr.update(visible=True),  # Окна\n",
    "            gr.update(visible=True)   # Удобства\n",
    "        ]\n",
    "\n",
    "\n",
    "# Создаем интерфейс Gradio\n",
    "with gr.Blocks() as demo:\n",
    "    ad_type = gr.Radio([\"продать\", \"сдать длительно\", \"сдать суточно\"], label=\"Тип объявления\")\n",
    "    property_type = gr.Dropdown([\"квартира\", \"комната\", \"дом\", \"коммерческое\", \"гараж\", \"участок\"], label=\"Тип недвижимости\")\n",
    "    city = gr.Textbox(label=\"Город\")\n",
    "    address = gr.Textbox(label=\"Адрес\")\n",
    "    year = gr.Number(label=\"Год постройки\")\n",
    "    ceiling_height = gr.Number(label=\"Высота потолков\")\n",
    "    parking_type = gr.Radio([\"закрытая\", \"подземная\", \"открытая\"], label=\"Тип парковки\")\n",
    "    house_type = gr.Radio([\"кирпич\", \"монолит\", \"кирпич-монолит\", \"панель\", \"блок\"], label=\"Тип дома\")\n",
    "    rooms = gr.Slider(minimum=0, maximum=7, step=1, label=\"Комнаты\")\n",
    "    area = gr.Textbox(label=\"Площадь\")\n",
    "    floor = gr.Textbox(label=\"Этаж (текущий/всего)\")\n",
    "    status = gr.Radio([\"апартаменты\", \"жилое помещение\"], label=\"Статус\")\n",
    "    bathroom = gr.Radio([\"совмещенный\", \"раздельный\", \"более одного\"], label=\"Санузел\")\n",
    "    balcony = gr.Radio([\"нет\", \"балкон\", \"лоджия\", \"несколько\"], label=\"Балкон\")\n",
    "    renovation = gr.Radio([\"косметический\", \"евро\", \"дизайнерский\", \"требуется\"], label=\"Ремонт\")\n",
    "    windows = gr.Radio([\"во двор\", \"на улицу\"], label=\"Окна\")\n",
    "    amenities = gr.CheckboxGroup([\"интернет\", \"холодильник\", \"мебель на кухне\", \"кондиционер\", \"мебель в квартире\", \"лифт\", \"мусоропровод\", \"консьерж\", \"закрытая территория\"], label=\"Удобства\")\n",
    "    \n",
    "    submit_btn = gr.Button(\"Submit\")\n",
    "    result = gr.Textbox(label=\"Результат\")\n",
    "\n",
    "    ad_type.change(update_property_type_choices, inputs=ad_type, outputs=property_type)\n",
    "    property_type.change(update_visibility, inputs=property_type, outputs=[area, rooms, house_type, floor, status, bathroom, balcony, renovation, windows, amenities])\n",
    "    \n",
    "    submit_btn.click(parse_real_estate_data, inputs=[ad_type, property_type, city, address, year, ceiling_height, parking_type, house_type, rooms, area, floor, status, bathroom, balcony, renovation, windows, amenities], outputs=result)\n",
    "\n",
    "    file_input = gr.File(label=\"Выберите изображения\", file_count=\"multiple\", type=\"filepath\")\n",
    "    \n",
    "    generate_button = gr.Button(\"Сгенерировать описание\")\n",
    "    output_text = gr.Textbox(label=\"Описание\")\n",
    "    \n",
    "    generate_button.click(process_images, inputs=[file_input, result], outputs=output_text)\n",
    "\n",
    "    \n",
    "# Запускаем интерфейс\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661dfece-c5a2-42f6-9ba2-0f248c75f11f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8274baa9-0c0a-49da-83a5-389cc9c3b8b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3ef275-4189-4a1e-89f0-1f823e4ce967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
